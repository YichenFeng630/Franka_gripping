# é¡¹ç›®å¯¹æ ‡åˆ†æ - ä¸Franka_Panda_Color_Sorting_Robotçš„å¯¹é½

**Date**: 2026-01-05  
**ç›®æ ‡**: å°†ç°æœ‰ROS1é¡¹ç›®ä¸reference projectçš„ROS2é¡¹ç›®ç‰¹æ€§è¿›è¡Œå¯¹é½

---

## ğŸ“Š é¡¹ç›®å¯¹æ¯”æ¦‚è§ˆ

| æ–¹é¢ | ç°æœ‰é¡¹ç›® (ROS1) | Reference (ROS2) | çŠ¶æ€ |
|------|----------------|------------------|------|
| **æ¡†æ¶ç‰ˆæœ¬** | ROS1 (melodic) | ROS2 (humble) | âš ï¸ éœ€è¦ROS2è¿ç§» |
| **ç›¸æœºç³»ç»Ÿ** | ZED2 (end-effector) | Generic RGB (simulated) | âš ï¸ å¯ä¼˜åŒ– |
| **è§†è§‰å¤„ç†** | åœ¨å»ºï¼ˆVISION_SETUP.mdï¼‰ | OpenCVè‰²å½©æ£€æµ‹ | âœ… å…¼å®¹ |
| **è¿åŠ¨è§„åˆ’** | MoveIt + moveit_commander | PyMoveIt2 | âš ï¸ éœ€è¦å‡çº§ |
| **å¤¹çˆªæ§åˆ¶** | franka_gripper actions | GripperInterface (custom) | âœ… å…¼å®¹ |
| **æ‹¾å–ç­–ç•¥** | åŠ¨æ€è®¡ç®— | é¢„å®šä¹‰joint positions | âš ï¸ æ··åˆæ–¹æ¡ˆ |
| **é¢œè‰²åˆ†ç±»** | 4è‰² (R,B,G,Y) | 3è‰² (R,G,B) | âœ… å…¼å®¹ |
| **æ”¾ç½®ç›®æ ‡** | åˆ†ç±»ç®± (bins) | å•ä¸€dropä½ç½® | âœ… æ‰©å±• |

---

## ğŸ¥ ç›¸æœºç³»ç»Ÿå¯¹æ¯”

### ç°æœ‰é¡¹ç›® (ZED2)

**ä¼˜ç‚¹**:
- âœ… ç«‹ä½“è§†è§‰ï¼ŒçœŸå®æ·±åº¦ä¼°è®¡
- âœ… æœ«ç«¯æ‰§è¡Œå™¨å®‰è£…ï¼Œè‡ªæˆ‘é®æŒ¡å¯æ§
- âœ… ç‰©ç†çœŸå®æ€§å¼º
- âœ… å®é™…éƒ¨ç½²å¯è¡Œ

**é…ç½®å‚æ•°**:
```yaml
ç›¸æœº: ZED2 (Stereolabs)
ä½ç½®: panda_hand æœ«ç«¯
å®‰è£…: è‡ªå®šä¹‰æ”¯æ¶
åŸºçº¿: 120mm
åˆ†è¾¨ç‡: 2560Ã—1440 @ 30fps
å†…å‚: 
  fx: ç”¨ZED2 SDKæä¾›
  fy: ç”¨ZED2 SDKæä¾›
  cx, cy: ä»æ ‡å®šè·å–
```

### Referenceé¡¹ç›® (Generic RGB)

**ç‰¹ç‚¹**:
- âœ… ç®€åŒ–æ¨¡å‹ï¼Œæ˜“äºè°ƒè¯•
- âœ… ä»¿çœŸå‹å¥½
- âœ… å›ºå®šå†…å‚
- âŒ æ— çœŸå®æ·±åº¦ä¼°è®¡

**é…ç½®å‚æ•°**:
```yaml
ç›¸æœº: Generic RGB (Gazebo plugin)
ä½ç½®: å›ºå®šæˆ–æœ«ç«¯
å†…å‚: ç¡¬ç¼–ç 
  fx: 585.0
  fy: 588.0
  cx: 320.0
  cy: 160.0
æ·±åº¦: å‡è®¾å¸¸æ•° Z = 0.1
```

---

## ğŸ”— å¯å¯¹é½çš„æ¨¡å—

### 1. è‰²å½©æ£€æµ‹æ¨¡å— âœ… é«˜åº¦å…¼å®¹

**Referenceçš„ä¼˜åŠ¿**:
- HSVè‰²å½©ç©ºé—´æ˜ç¡®å®šä¹‰
- åˆ†ç¦»çš„ColorDetector ROS2èŠ‚ç‚¹
- å‘å¸ƒstd_msgs/Stringæ ¼å¼åæ ‡

**å¯¹é½å»ºè®®**:
```python
# å‚è€ƒcolor_detector.pyçš„æ¨¡å¼

color_ranges = {
    "R": [(0, 120, 70), (10, 255, 255)],      # çº¢è‰²
    "G": [(55, 200, 200), (60, 255, 255)],    # ç»¿è‰²
    "B": [(90, 200, 200), (128, 255, 255)],   # è“è‰²
    "Y": [(20, 120, 70), (40, 255, 255)]      # é»„è‰²ï¼ˆæ–°å¢ï¼‰
}

# å‘å¸ƒæ ¼å¼: "R,x,y,z" æˆ– "G,x,y,z"
self.coords_pub.publish(String(data=f"{color_id},{cx_pix},{cy_pix},{Z}"))
```

---

### 2. è¿åŠ¨è§„åˆ’æ¥å£ âš ï¸ éœ€è¦ROS2å‡çº§

**Referenceçš„ä¼˜åŠ¿**:
- PyMoveIt2 æä¾›é«˜çº§API
- é€šç”¨çš„gripper_interface
- Smooth joint transitions

**å¯¹é½å»ºè®® (ä¿æŒROS1å…¼å®¹)**:
```python
# å‚è€ƒpick_and_place.pyçš„æ¨¡å¼ï¼Œä¿æŒROS1å…¼å®¹

# é¢„å®šä¹‰å…³é”®poseï¼ˆç±»ä¼¼Referenceï¼‰
self.start_joints = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -2.18]
self.home_joints  = [0.0, 0.0, 0.0, -1.57, 0.0, 1.57, 0.87]
self.drop_joints_bin1 = [...]  # æ¯ä¸ªbinå®šä¹‰

# ä½¿ç”¨MoveIt commanderæ‰§è¡Œ
group.go(self.home_joints, wait=True)
```

---

### 3. å¤¹çˆªæ§åˆ¶æ¥å£ âœ… å¯ç›´æ¥è¿ç§»

**Referenceçš„æ–¹å¼**:
```python
self.gripper = GripperInterface(
    node=self,
    gripper_joint_names=panda.gripper_joint_names(),
    open_gripper_joint_positions=panda.OPEN_GRIPPER_JOINT_POSITIONS,
    closed_gripper_joint_positions=panda.CLOSED_GRIPPER_JOINT_POSITIONS,
    gripper_group_name=panda.MOVE_GROUP_GRIPPER,
)

# æ§åˆ¶å‘½ä»¤
self.gripper.open()
self.gripper.close()
self.gripper.move_to_position(0.02)  # å®½åº¦
```

**å¯¹é½å»ºè®® (ROS1å…¼å®¹)**:
- å‚è€ƒç°æœ‰v4_demo.pyçš„close_gripper()å®ç°
- æ·»åŠ open_gripper()æ–¹æ³•
- ç»Ÿä¸€gripper state feedback

---

### 4. å¤šç›®æ ‡æ”¾ç½®ç­–ç•¥ âœ… å¯æ‰©å±•

**Referenceçš„å±€é™**:
- åªæœ‰å•ä¸€drop_jointsï¼ˆä¸€ä¸ªæ”¾ç½®ä½ç½®ï¼‰

**ç°æœ‰é¡¹ç›®çš„ä¼˜åŠ¿**:
- SortingStateMachineæ”¯æŒå¤šbin
- åŠ¨æ€binä½ç½®è®¡ç®—

**å¯¹é½å»ºè®®**:
```python
# ä¿æŒç°æœ‰çš„bin-based approachï¼Œå‚è€ƒReferenceçš„jointé¢„å®šä¹‰æ€è·¯

BIN_POSITIONS = {
    'BIN_1': {
        'home': [0.0, 0.0, 0.0, -1.57, 0.0, 1.57, 0.87],
        'drop': [-2.71, 0.52, -0.35, -2.16, 0.77, 2.84, 0.12],
    },
    'BIN_2': {
        'home': [0.0, 0.0, 0.0, -1.57, 0.0, 1.57, 0.87],
        'drop': [-1.57, 0.52, -0.35, -2.16, 0.77, 2.84, 0.12],
    },
    'BIN_3': {
        'home': [0.0, 0.0, 0.0, -1.57, 0.0, 1.57, 0.87],
        'drop': [0.52, 0.52, -0.35, -2.16, 0.77, 2.84, 0.12],
    },
}
```

---

## ğŸ”„ ä¼˜å…ˆçº§å¯¹é½å»ºè®®

### ç¬¬1ä¼˜å…ˆçº§ï¼šè§†è§‰æ¨¡å—å¼ºåŒ–

**ç›®æ ‡**: é‡‡ç”¨Referenceé¡¹ç›®çš„è‰²å½©æ£€æµ‹è®¾è®¡æ¨¡å¼

**ä»»åŠ¡**:
1. âœ… å‚è€ƒcolor_detector.pyçš„HSVèŒƒå›´å®šä¹‰
2. âœ… ç»Ÿä¸€åæ ‡å‘å¸ƒæ ¼å¼ (String: "COLOR,x,y,z")
3. âœ… æ·»åŠ TF2å˜æ¢æ”¯æŒï¼ˆReferenceå·²æœ‰ï¼‰
4. â­• æ·»åŠ æ·±åº¦ä¼°è®¡é€‰é¡¹ï¼ˆä»ZEDæˆ–å‡è®¾å€¼ï¼‰

**æ–‡ä»¶**:
- `/opt/ros_ws/src/panda_grasp_planning/modules/perception/perception_node.py` (æ–°å»º)
- `/opt/ros_ws/src/panda_grasp_planning/modules/perception/color_detector.py` (å‚è€ƒReference)

---

### ç¬¬2ä¼˜å…ˆçº§ï¼šè¿åŠ¨æ¥å£æ ‡å‡†åŒ–

**ç›®æ ‡**: å°†v4_demo.pyä¸Referenceçš„pick_and_placeè®¾è®¡å¯¹é½

**ä»»åŠ¡**:
1. âœ… å®šä¹‰é¢„å®šä¹‰joint positionsï¼ˆå‚è€ƒReferenceçš„start/home/dropï¼‰
2. âœ… åˆ†ç¦»gripperæ§åˆ¶ä¸ºç‹¬ç«‹æ¥å£
3. âœ… å®ç°smooth trajectory transitions
4. â­• ä¿æŒROS1å…¼å®¹ï¼ˆå¯é€‰ROS2è¿ç§»è·¯å¾„ï¼‰

**æ–‡ä»¶**:
- `/opt/ros_ws/src/panda_grasp_planning/scripts/v4_demo.py` (ä¼˜åŒ–)
- `/opt/ros_ws/src/panda_grasp_planning/config/motion_profiles.yaml` (æ–°å»º)

---

### ç¬¬3ä¼˜å…ˆçº§ï¼šROS2è¿ç§»è§„åˆ’ï¼ˆæœªæ¥ï¼‰

**ç›®æ ‡**: æ”¯æŒROS2æ¡†æ¶

**ä»»åŠ¡** (å»¶å):
- [ ] åˆ›å»ºROS2è½¬æ¢å±‚
- [ ] è¿ç§»åˆ°PyMoveIt2
- [ ] å‚è€ƒReferenceé¡¹ç›®çš„ROS2ç»“æ„

---

## ğŸ“‹ å…·ä½“å®ç°æ­¥éª¤

### Step 1: å¢å¼ºè‰²å½©æ£€æµ‹æ¨¡å—

```python
# æ–°æ–‡ä»¶: modules/perception/color_detector_enhanced.py

class EnhancedColorDetector:
    def __init__(self):
        self.color_ranges_hsv = {
            "R": [(0, 120, 70), (10, 255, 255)],
            "G": [(55, 200, 200), (60, 255, 255)],
            "B": [(90, 200, 200), (128, 255, 255)],
            "Y": [(20, 120, 70), (40, 255, 255)],
        }
    
    def detect_colors(self, frame):
        """å‚è€ƒReferenceçš„detecté€»è¾‘"""
        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
        results = []
        for color_id, (lower, upper) in self.color_ranges_hsv.items():
            mask = cv2.inRange(hsv, np.array(lower), np.array(upper))
            mask = cv2.erode(mask, None, iterations=2)
            mask = cv2.dilate(mask, None, iterations=2)
            
            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            for cnt in contours:
                if cv2.contourArea(cnt) > 100:  # æœ€å°é¢ç§¯é˜ˆå€¼
                    x, y, w, h = cv2.boundingRect(cnt)
                    cx, cy = x + w//2, y + h//2
                    results.append({
                        'color': color_id,
                        'pixel': (cx, cy),
                        'bbox': (x, y, w, h),
                    })
        return results
```

### Step 2: ç»Ÿä¸€åæ ‡å‘å¸ƒæ¥å£

```python
# å‚è€ƒReferenceçš„å‘å¸ƒæ ¼å¼

def publish_coordinates(self, color_id, world_x, world_y, world_z):
    """
    å‘å¸ƒæ ¼å¼: "COLOR,x,y,z"
    å¯¹åº”Reference: String("/color_coordinates")
    """
    msg = String(data=f"{color_id},{world_x:.4f},{world_y:.4f},{world_z:.4f}")
    self.coords_pub.publish(msg)
```

### Step 3: ä¼˜åŒ–v4_demo.pyçš„è¿åŠ¨éƒ¨åˆ†

```python
# å‚è€ƒReferenceçš„é¢„å®šä¹‰positions

class V4DemoEnhanced:
    def __init__(self):
        # å…³é”®positionsï¼ˆå‚è€ƒReferenceï¼‰
        self.motion_profiles = {
            'start': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -2.18],
            'home': [0.0, 0.0, 0.0, -1.57, 0.0, 1.57, 0.87],
            'bin_1': [-2.71, 0.52, -0.35, -2.16, 0.77, 2.84, 0.12],
            'bin_2': [-1.57, 0.52, -0.35, -2.16, 0.77, 2.84, 0.12],
            'bin_3': [0.52, 0.52, -0.35, -2.16, 0.77, 2.84, 0.12],
        }
    
    def move_to_predefined(self, profile_name, wait=True):
        """å‚è€ƒReferenceçš„move_to_configuration"""
        if profile_name not in self.motion_profiles:
            raise ValueError(f"Unknown profile: {profile_name}")
        
        target_joints = self.motion_profiles[profile_name]
        self.group.go(target_joints, wait=wait)
        if wait:
            self.group.stop()
```

---

## ğŸ¯ å¯¹é½å®Œæˆæ¸…å•

- [ ] **æ„ŸçŸ¥æ¨¡å—**:
  - [ ] é‡‡ç”¨Referenceçš„HSVè‰²å½©èŒƒå›´
  - [ ] ç»Ÿä¸€Stringæ ¼å¼å‘å¸ƒåæ ‡
  - [ ] æ·»åŠ TF2æ”¯æŒ
  
- [ ] **è¿åŠ¨æ¨¡å—**:
  - [ ] å®šä¹‰é¢„å®šä¹‰joint positions
  - [ ] åˆ†ç¦»gripperæ¥å£
  - [ ] å®ç°smooth transitions
  
- [ ] **æµ‹è¯•éªŒè¯**:
  - [ ] é¢œè‰²æ£€æµ‹å‡†ç¡®ç‡ â‰¥95%
  - [ ] æ‹¾å–æˆåŠŸç‡ â‰¥90% (å¯¹é½Reference)
  - [ ] å¤šç›®æ ‡æ”¾ç½®åŠŸèƒ½å®Œæ•´
  
- [ ] **æ–‡æ¡£**:
  - [ ] VISION_ENHANCED.md
  - [ ] MOTION_PROFILES.md
  - [ ] ROS2è¿ç§»æŒ‡å— (æœªæ¥)

---

## ğŸš€ åç»­å¯é€‰å‡çº§

### ROS2å®Œå…¨è¿ç§»
å‚è€ƒReferenceé¡¹ç›®çš„å®Œæ•´ROS2ç»“æ„ï¼š
- `panda_vision` â†’ ROS2åŒ– perception node
- `pymoveit2` â†’ é«˜çº§APIæ›¿ä»£MoveIt commander
- `panda_controller` â†’ æ–°çš„controlèŠ‚ç‚¹

### ç¡¬ä»¶å‡çº§é€‰é¡¹
1. **ä¿æŒZED2**: å¾—åˆ°çœŸå®æ·±åº¦ï¼Œç¬¦åˆéƒ¨ç½²éœ€æ±‚
2. **åˆ‡æ¢åˆ°generic**: ç®€åŒ–ä»¿çœŸï¼ŒåŠ é€Ÿå¼€å‘
3. **æ··åˆæ–¹æ¡ˆ**: ä»¿çœŸç”¨genericï¼Œéƒ¨ç½²ç”¨ZED2

---

**ç”Ÿæˆæ—¶é—´**: 2026-01-05  
**ä¸‹ä¸€æ­¥**: å®¡æ‰¹å¯¹é½è®¡åˆ’ï¼Œç¡®å®šä¼˜å…ˆçº§é¡ºåº

